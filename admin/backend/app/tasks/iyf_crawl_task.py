"""
IYF è§†é¢‘å®šæ—¶çˆ¬å–ä»»åŠ¡
ä½¿ç”¨ Playwright æ— å¤´æµè§ˆå™¨çˆ¬å–è§†é¢‘æ•°æ®
"""
from datetime import datetime
from typing import List, Optional
import logging
import threading
import asyncio

from sqlmodel import Session, select

from app.core.db import engine
from app.core.config import settings
from app.core.logger import init_logger
from app.spiders.iyf_spider import run_iyf_spider_async
from app.models.iyfVideo import IyfVideo, IyfVideoCreate
from app.crud.iyfVideo_crud import IyfVideoCRUD
from app.crud.iyfEmailHistory_crud import IyfEmailHistoryCRUD

init_logger()
logger = logging.getLogger(__name__)


def get_last_latest_iyf_id() -> Optional[str]:
    """è·å–ä¸Šæ¬¡å‘é€é‚®ä»¶æ—¶è®°å½•çš„æœ€æ–°è§†é¢‘ID"""
    with Session(engine) as session:
        crud = IyfEmailHistoryCRUD(session, user_id=1, dept_id=0)
        return crud.get_latest_iyf_id()


def filter_new_videos(all_videos: List[dict], last_latest_iyf_id: Optional[str]) -> List[dict]:
    """
    æ ¹æ®ä¸Šæ¬¡è®°å½•çš„æœ€æ–°è§†é¢‘IDï¼Œç­›é€‰å‡ºæ–°è§†é¢‘
    
    ç”µå½±æŒ‰åŠ å…¥æ—¶é—´å€’åºæ’åˆ—ï¼Œåˆ—è¡¨ç¬¬ä¸€ä¸ªæ˜¯æœ€æ–°çš„
    éå†ç›´åˆ°é‡åˆ°ä¸Šæ¬¡çš„latest_iyf_idï¼Œä¹‹å‰çš„éƒ½æ˜¯æ–°è§†é¢‘
    """
    if not last_latest_iyf_id:
        # ç¬¬ä¸€æ¬¡è¿è¡Œï¼Œæ‰€æœ‰è§†é¢‘éƒ½æ˜¯æ–°çš„
        logger.info("[Filter] No previous latest_iyf_id found, all videos are new")
        return all_videos
    
    new_videos = []
    for video in all_videos:
        iyf_id = video.get("iyf_id")
        if iyf_id == last_latest_iyf_id:
            # é‡åˆ°ä¸Šæ¬¡çš„æœ€æ–°IDï¼Œåœæ­¢
            logger.info(f"[Filter] Found previous latest_iyf_id: {last_latest_iyf_id}, stopping")
            break
        new_videos.append(video)
    
    logger.info(f"[Filter] Found {len(new_videos)} new videos (before {last_latest_iyf_id})")
    return new_videos


class IYFDataProcessor:
    """å¤„ç†çˆ¬å–çš„æ•°æ®å¹¶å­˜å‚¨åˆ°æ•°æ®åº“"""
    
    def __init__(self, session: Session, user_id: int = 1, dept_id: int = 0):
        self.session = session
        self.user_id = user_id
        self.dept_id = dept_id
        self.video_crud = IyfVideoCRUD(session, user_id, dept_id)
        self.crawl_date = datetime.utcnow().strftime("%Y-%m-%d")
        self.new_videos = []
    
    def process_videos(self, videos: List[dict]) -> List[IyfVideo]:
        """å¤„ç†è§†é¢‘åˆ—è¡¨ï¼Œè¿”å›æ–°å¢çš„è§†é¢‘"""
        if not videos:
            logger.warning("No videos to process")
            return []
        
        new_videos = []
        for video_data in videos:
            new_video = self._upsert_video(video_data)
            if new_video:
                new_videos.append(new_video)
        
        # æäº¤äº‹åŠ¡
        self.session.commit()
        logger.info(f"Processed {len(videos)} videos, {len(new_videos)} new")
        
        self.new_videos.extend(new_videos)
        return new_videos
    
    def _upsert_video(self, video_data: dict) -> Optional[IyfVideo]:
        """æ›´æ–°æˆ–åˆ›å»ºè§†é¢‘è®°å½•"""
        iyf_id = video_data.get("iyf_id")
        if not iyf_id:
            return None
        
        # æ£€æŸ¥æ˜¯å¦å·²å­˜åœ¨
        existing = self.session.exec(
            select(IyfVideo).where(
                IyfVideo.iyf_id == iyf_id,
                IyfVideo.deleted == False
            )
        ).first()
        
        if existing:
            # æ›´æ–°ç°æœ‰è®°å½•
            from app.models.iyfVideo import IyfVideoUpdate
            update_data = IyfVideoUpdate(
                title=video_data.get("title"),
                cover_url=video_data.get("cover_url"),
                description=video_data.get("description"),
                category=video_data.get("category"),
                year=video_data.get("year"),
                region=video_data.get("region"),
                rating=video_data.get("rating"),
                view_count=video_data.get("view_count"),
                crawl_date=self.crawl_date,
                updater=str(self.user_id),
            )
            self.video_crud.update(existing, update_data)
            logger.debug(f"Updated video: {iyf_id} - {video_data.get('title')}")
            return None
        else:
            # åˆ›å»ºæ–°è®°å½•
            video_create = IyfVideoCreate(
                iyf_id=iyf_id,
                title=video_data.get("title", ""),
                cover_url=video_data.get("cover_url", ""),
                description=video_data.get("description", ""),
                category=video_data.get("category", ""),
                year=video_data.get("year", 0),
                region=video_data.get("region", ""),
                rating=video_data.get("rating", ""),
                view_count=video_data.get("view_count", 0),
                crawl_date=self.crawl_date,
                creator=str(self.user_id),
                dept_id=self.dept_id,
            )
            new_video = self.video_crud.create(video_create)
            logger.info(f"Created new video: {iyf_id} - {video_data.get('title')}")
            return new_video
    
    def get_new_videos(self) -> List[IyfVideo]:
        """è·å–æœ¬æ¬¡çˆ¬å–æ–°å¢çš„è§†é¢‘åˆ—è¡¨"""
        return self.new_videos


def get_categories_to_crawl() -> List[str]:
    """è·å–éœ€è¦çˆ¬å–çš„åˆ†ç±»åˆ—è¡¨"""
    return settings.iyf_categories_list


async def _crawl_category(category: str) -> List[dict]:
    """çˆ¬å–å•ä¸ªåˆ†ç±»"""
    logger.info(f"[Task] Crawling category: {category}")
    try:
        videos = await run_iyf_spider_async(category=category, headless=True)
        logger.info(f"[Task] Category {category}: got {len(videos)} videos")
        return videos
    except Exception as e:
        logger.error(f"[Task] Error crawling category {category}: {e}", exc_info=True)
        return []


async def _run_crawl_async(categories: List[str]) -> List[dict]:
    """å¼‚æ­¥è¿è¡Œæ‰€æœ‰åˆ†ç±»çš„çˆ¬å–"""
    all_videos = []
    
    for category in categories:
        videos = await _crawl_category(category)
        all_videos.extend(videos)
        # æ¯ä¸ªåˆ†ç±»ä¹‹é—´ç¨ä½œå»¶è¿Ÿ
        await asyncio.sleep(2)
    
    return all_videos


def _run_crawl_in_thread(categories: List[str]):
    """åœ¨çº¿ç¨‹ä¸­è¿è¡Œçˆ¬è™«ä»»åŠ¡"""
    logger.info(f"[Task] Starting crawl in thread for {len(categories)} categories")
    
    try:
        # è·å–ä¸Šæ¬¡è®°å½•çš„æœ€æ–°è§†é¢‘ID
        last_latest_iyf_id = get_last_latest_iyf_id()
        logger.info(f"[Task] Last latest_iyf_id: {last_latest_iyf_id or 'None (first run)'}")
        
        # è¿è¡Œå¼‚æ­¥çˆ¬å–
        all_videos = asyncio.run(_run_crawl_async(categories))
        
        logger.info("=" * 60)
        logger.info(f"[Task] All crawls completed. Got {len(all_videos)} videos")
        logger.info("=" * 60)
        
        if not all_videos:
            logger.warning("[Task] No videos collected!")
            return
        
        # è·å–æœ¬æ¬¡æœ€æ–°çš„è§†é¢‘IDï¼ˆåˆ—è¡¨ç¬¬ä¸€ä¸ªï¼‰
        current_latest_iyf_id = all_videos[0].get("iyf_id") if all_videos else None
        logger.info(f"[Task] Current latest_iyf_id: {current_latest_iyf_id}")
        
        # ğŸš€ ä¼˜åŒ–ï¼šå¦‚æœæœ€æ–°è§†é¢‘IDä¸ä¸Šæ¬¡ä¸€è‡´ï¼Œè¯´æ˜æ²¡æœ‰æ–°æ•°æ®ï¼Œç›´æ¥è¿”å›
        if last_latest_iyf_id and current_latest_iyf_id == last_latest_iyf_id:
            logger.info("=" * 60)
            logger.info(f"[Task] No new videos! Current latest_iyf_id ({current_latest_iyf_id}) matches last record.")
            logger.info("[Task] Skipping data processing and email notification.")
            logger.info("=" * 60)
            return
        
        # ç­›é€‰æ–°è§†é¢‘ï¼ˆåŸºäºä¸Šæ¬¡çš„latest_iyf_idï¼‰
        new_videos_to_notify = filter_new_videos(all_videos, last_latest_iyf_id)
        
        # åªå¤„ç†æ–°è§†é¢‘å…¥åº“
        if new_videos_to_notify:
            # å€’åºåå…¥åº“ï¼Œä¿è¯æ•°æ®åº“ id é¡ºåºä¸æ—¶é—´é¡ºåºä¸€è‡´
            # çˆ¬è™«è¿”å›: [æœ€æ–°, æ¬¡æ–°, ..., æ—§] â†’ å€’åº: [æ—§, ..., æ¬¡æ–°, æœ€æ–°]
            # å…¥åº“å: id å°çš„æ˜¯æ—§çš„ï¼Œid å¤§çš„æ˜¯æ–°çš„
            videos_to_save = list(reversed(new_videos_to_notify))
            logger.info(f"[Task] Saving {len(videos_to_save)} videos (reversed order for DB consistency)")
            
            with Session(engine) as session:
                processor = IYFDataProcessor(session, user_id=1, dept_id=0)
                processor.process_videos(videos_to_save)  # å€’åºå…¥åº“
        
        # æ•°æ®å…¥åº“å®Œæˆ
        logger.info("=" * 60)
        logger.info(f"[Task] IYF crawl task completed successfully")
        logger.info(f"[Task] New videos processed: {len(new_videos_to_notify)}")
        logger.info("=" * 60)
        
        # å¦‚æœæœ‰æ–°è§†é¢‘ï¼Œå‘é€é‚®ä»¶é€šçŸ¥
        if new_videos_to_notify and len(new_videos_to_notify) > 0:
            try:
                from app.tasks.iyf_email_task import send_new_video_emails
                
                logger.info(f"[Task] Sending email notification for {len(new_videos_to_notify)} new videos...")
                # ä¼ å…¥æ–°è§†é¢‘åˆ—è¡¨å’Œå½“å‰æœ€æ–°çš„iyf_id
                success_count = send_new_video_emails(new_videos_to_notify, current_latest_iyf_id)
                logger.info(f"[Task] Email notification completed, sent {success_count} emails")
            except Exception as e:
                logger.error(f"[Task] Error sending email notification: {e}", exc_info=True)
        else:
            logger.info("[Task] No new videos to notify")
        
        logger.info("[Task] Crawl thread completed")
        
    except Exception as e:
        logger.error(f"Error in crawl thread: {e}", exc_info=True)
        raise


def iyf_crawl_task():
    """å®šæ—¶ä»»åŠ¡ï¼šçˆ¬å– IYF è§†é¢‘æ•°æ®"""
    logger.info("=" * 60)
    logger.info("Starting IYF crawl task (Playwright)")
    logger.info("=" * 60)
    
    try:
        categories = get_categories_to_crawl()
        
        if not categories:
            logger.warning("No categories found to crawl")
            return
        
        logger.info(f"[Task] Found {len(categories)} categories to crawl: {categories}")
        
        # åœ¨åå°çº¿ç¨‹ä¸­è¿è¡Œçˆ¬è™«
        crawl_thread = threading.Thread(
            target=_run_crawl_in_thread,
            args=(categories,),
            daemon=True,
            name="IYFCrawlThread"
        )
        crawl_thread.start()
        
        logger.info("[Task] Crawl thread started in background, returning immediately")
        
    except Exception as e:
        logger.error(f"Error in IYF crawl task: {e}", exc_info=True)
        raise
